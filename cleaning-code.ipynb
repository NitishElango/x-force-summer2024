{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdatetime\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m files\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mzipfile\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import datetime\n",
    "from google.colab import files\n",
    "import zipfile\n",
    "import os\n",
    "from sklearn.cluster import DBSCAN\n",
    "from matplotlib import pyplot as plt\n",
    "from geopy.distance import geodesic\n",
    "\n",
    "#from geopy.distance import geodesic (need if we want to normalize to the globe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Special thanks to Scott\n",
    "#Region of interest\n",
    "min_lat = 4\n",
    "max_lat = 26\n",
    "min_lon = 110\n",
    "max_lon = 130\n",
    "#May need to adjust boundaries. Currently barely contains Taiwan, but has a lot of the Phillipine Sea\n",
    "\n",
    "#Remove data outside of our box\n",
    "def spatial_filter(x, y_0, y_1, x_0, x_1):\n",
    "  return x[(x['Latitude'] >= min_lat) &\n",
    "                     (x['Latitude'] <= max_lat) &\n",
    "                     (x['Longitude'] >= min_lon) &\n",
    "                     (x['Longitude'] <= max_lon)]\n",
    "\n",
    "# for labeling rows that occur during an exercise\n",
    "def label_exercise(date):\n",
    "  date = pd.to_datetime(date, format=' %Y %b %d %H:%M:%S UTC', utc = True)\n",
    "  date_ranges = [[pd.to_datetime(\"2019-08-01 00:00:00\", format='%Y-%m-%d %H:%M:%S', utc = True), pd.to_datetime(\"2019-08-30 00:00:00\", format='%Y-%m-%d %H:%M:%S', utc = True)],\n",
    "                 [pd.to_datetime(\"2020-10-01 00:00:00\", format='%Y-%m-%d %H:%M:%S', utc = True), pd.to_datetime(\"2020-10-31 00:00:00\", format='%Y-%m-%d %H:%M:%S', utc = True)],\n",
    "                 [pd.to_datetime(\"2021-11-01 00:00:00\", format='%Y-%m-%d %H:%M:%S', utc = True), pd.to_datetime(\"2021-11-30 00:00:00\", format='%Y-%m-%d %H:%M:%S', utc = True)],\n",
    "                 [pd.to_datetime(\"2022-08-01 00:00:00\", format='%Y-%m-%d %H:%M:%S', utc = True), pd.to_datetime(\"2022-08-30 00:00:00\", format='%Y-%m-%d %H:%M:%S', utc = True)],\n",
    "                 [pd.to_datetime(\"2022-04-01 00:00:00\", format='%Y-%m-%d %H:%M:%S', utc = True), pd.to_datetime(\"2022-04-30 00:00:00\", format='%Y-%m-%d %H:%M:%S', utc = True)]\n",
    "                 ]\n",
    "  for i in range(len(date_ranges)):\n",
    "    if date >= date_ranges[i][0] and date < date_ranges[i][1]:\n",
    "      return i\n",
    "  return -1\n",
    "\n",
    "def convert_to_datetime(x):\n",
    "  return pd.to_datetime(x, format=' %Y %b %d %H:%M:%S UTC', utc = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################ CLEANING CODE ################################\n",
    "\n",
    "#loads data into a list of dataframes\n",
    "def load_and_process_data():\n",
    "  #upload a .zip file of seavision data\n",
    "  uploaded = files.upload()\n",
    "  #extract files from zip\n",
    "  for file_name in uploaded.keys():\n",
    "    if file_name.endswith('.zip'):\n",
    "        with zipfile.ZipFile(file_name, 'r') as zip_ref:\n",
    "            zip_ref.extractall('/content/uploaded_folder')\n",
    "  datalist = [] #list of dataframes that we will use to store all of our separate files\n",
    "  #iterate over all files in the uploadedfolder\n",
    "  folder_path = '/content/uploaded_folder'\n",
    "  for root, directories, filenames in os.walk(folder_path):\n",
    "    for file in filenames:\n",
    "      file_path = os.path.join(root, file)\n",
    "      df = pd.read_csv(file_path)\n",
    "      df.dropna(subset = ['MMSI', 'TimeOfFix', 'Latitude', 'Longitude', 'SOG', 'Heading'], inplace = True)\n",
    "      df = spatial_filter(df, min_lat, max_lat, min_lon, max_lon)\n",
    "      #mask = (type(df['SOG']) != str) & (type(df['Heading']) != str) & (type(df['Latitude']) != str) & (type(df['Longitude']) != str)\n",
    "      df = df[df['SOG'] != ' null']\n",
    "      df = df[df['Heading'] != ' null']\n",
    "      df = df[df['Latitude'] != ' null']\n",
    "      df = df[df['Longitude'] != ' null']\n",
    "      df.index = df.pop('MMSI')\n",
    "      df[\"Exercise\"] = df[\"TimeOfFix\"].apply(label_exercise)\n",
    "      df[\"TimeOfFix\"] = df[\"TimeOfFix\"].apply(convert_to_datetime)\n",
    "      #add dataframe to list\n",
    "\n",
    "      datalist.append(df)\n",
    "  print(\"Data Read and Processed into List\")\n",
    "\n",
    "  return datalist\n",
    "\n",
    "#takes the first entry from each dataframe in datalist and combines them into one dataframe\n",
    "#in place\n",
    "def findfirst(inputlist):\n",
    "  templist = []\n",
    "  for x in inputlist:\n",
    "    templist.append(x.head(1))\n",
    "  return pd.concat(templist)\n",
    "\n",
    "# combines all processed data into one massive csv\n",
    "def alldata(inputlist):\n",
    "  return pd.concat(inputlist)\n",
    "\n",
    "#isolates data that doesn't occur during an exercise\n",
    "def cleardata(inputlist):\n",
    "  templist = []\n",
    "  for x in inputlist:\n",
    "    x = x[x[\"Exercise\"] == -1]\n",
    "    templist.append(x)\n",
    "  return pd.concat(templist)\n",
    "\n",
    "#isolates exercise data\n",
    "def exercisedata(inputlist):\n",
    "  templist = []\n",
    "  for x in inputlist:\n",
    "    x = x[x[\"Exercise\"] != -1]\n",
    "    templist.append(x)\n",
    "  return pd.concat(templist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################## LOAD DATA ###########################################\n",
    "###################### TAKES A LONG TIME #######################################\n",
    "\n",
    "originaldata = load_and_process_data()\n",
    "first_ships = findfirst(originaldata)\n",
    "total_ships = alldata(originaldata)\n",
    "exercise_ships = exercisedata(originaldata)\n",
    "cleared_ships = cleardata(originaldata)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
