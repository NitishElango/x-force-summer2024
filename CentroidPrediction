#imports!
import pandas as pd
import numpy as np
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, LSTM
from google.colab import files

# Descaling function for Barrett's custom normalization
def descale_lat(scaled_lat):
    return (scaled_lat * 10) + 14

def descale_lon(scaled_lon):
    return (scaled_lon * 10) + 120

#Upload and processing user's data file
uploaded = files.upload()
file_name = list(uploaded.keys())[0]
data = pd.read_csv(file_name)

# redefining all points in avgLat and avgLon column to be the actual coordinate values
data['AvgLat'] = descale_lat(data['AvgLat'])
data['AvgLon'] = descale_lon(data['AvgLon'])

################# Testing Code #########################
# # Print to check descaled values
# print("Descaled values:")
# print(data[['AvgLat', 'AvgLon']].head())

#using MinMaxScaler to get values in range from [0,1], 
#This is done to help the model train faster and more efficiently as we have a standard range of values
scaler = MinMaxScaler()
data[['AvgLat', 'AvgLon', 'AvgHead']] = scaler.fit_transform(data[['AvgLat', 'AvgLon', 'AvgHead']])

################# Testing Code #########################
## Print to check normalized values
# print("Normalized values:")
# print(data[['AvgLat', 'AvgLon', 'AvgHead']].head())

features = ['AvgLat', 'AvgLon', 'AvgHead']
target = ['AvgLat', 'AvgLon', 'AvgHead']

X = np.array(data[features]).reshape((data.shape[0], 1, 3))
y = np.array(data[target])

# Creating and Compiling the LSTM model 
model = Sequential()
model.add(LSTM(128, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))
model.add(LSTM(64))
model.add(Dense(3))
model.compile(optimizer='adam', loss='mean_squared_error', metrics=[tf.keras.metrics.MeanAbsoluteError()])
history = model.fit(X, y, epochs=100, validation_split=0.2, verbose=1)

# Predicting values
y_pred = model.predict(X)

# Setting up loss functions - overkill :o
mse = mean_squared_error(y, y_pred)
mae = mean_absolute_error(y, y_pred)
print(f'Mean Squared Error: {mse}')
print(f'Mean Absolute Error: {mae}')

# Inversing the predicted and actual values to get the proper coordinate values again
y_pred_inverse = scaler.inverse_transform(y_pred)
y_actual_inverse = scaler.inverse_transform(y)

################# Testing Code #########################
# # Print to check inverse transformed values
# print("Inverse transformed predicted values:")
# print(y_pred_inverse[:5])
# print("Inverse transformed actual values:")
# print(y_actual_inverse[:5])

# Mapping predictions back to respecitve columns
data['Pred_AvgLat'] = y_pred_inverse[:, 0]
data['Pred_AvgLon'] = y_pred_inverse[:, 1]
data['Pred_AvgHead'] = y_pred_inverse[:, 2]
data['Actual_AvgLat'] = y_actual_inverse[:, 0]
data['Actual_AvgLon'] = y_actual_inverse[:, 1]
data['Actual_AvgHead'] = y_actual_inverse[:, 2]

# Saving and downloading CSV
output_df = data[['Hour', 'Cluster', 'Actual_AvgLat', 'Actual_AvgLon', 'Actual_AvgHead', 'Pred_AvgLat', 'Pred_AvgLon', 'Pred_AvgHead']].copy()
output_file_name = 'predictions_output.csv'
output_df.to_csv(output_file_name, index=False)
files.download(output_file_name)
