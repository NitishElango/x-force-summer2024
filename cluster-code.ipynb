{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9266c3b8-b0f5-4a96-83b5-d9f401e6f4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import datetime\n",
    "from google.colab import files\n",
    "import zipfile\n",
    "import os\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.metrics import silhouette_score\n",
    "from matplotlib import pyplot as plt\n",
    "from geopy.distance import geodesic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c4ac81-937e-422b-a566-3c64323de7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### SPLIT BY TIME PERIOD ###############################\n",
    "\n",
    "#Take a single dataframe of ship data and split it into a list corresponding to a time frame\n",
    "def timesplit(dataframe):\n",
    "  series = []\n",
    "  dataframe = dataframe.sort_values(by='TimeOfFix')\n",
    "  starttime = dataframe.iloc[0]['TimeOfFix']\n",
    "  endtime = dataframe.iloc[-1]['TimeOfFix']\n",
    "  t = pd.date_range(starttime, endtime, freq='H')\n",
    "  for i in range(len(t) - 1):\n",
    "    newframe = dataframe[(dataframe['TimeOfFix'] >= t[i]) & (dataframe['TimeOfFix'] < t[i+1])]\n",
    "    newframe = newframe[~newframe.index.duplicated(keep='last')]\n",
    "    series.append(newframe)\n",
    "  return series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61527f6a-5b0a-4086-8fb8-411ef13f968a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clustermetric(x, y):\n",
    "  c1, c2, c3 = 0.5, 0.2, 0.3 # constants\n",
    "  x_coords = np.column_stack((x[0], x[1]))\n",
    "  y_coords = np.column_stack((y[0], y[1]))\n",
    "  latlongdiff = np.sqrt(np.sum((x_coords - y_coords)**2))\n",
    "  sogdiff = abs(x[2] - y[2])\n",
    "  headingdiff = 2 - abs(1 - (abs(x[3] - y[3])/180)) # accounts for distance in rotation\n",
    "  return latlongdiff*headingdiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75b2f94-b392-4663-9729-70709acd2e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code for calculating intra-cluster distance\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "import numpy as np\n",
    "\n",
    "# Function to calculate average intra-cluster distance for each cluster using DBSCAN\n",
    "def calculate_intracluster_distance_dbscan(data, eps, min_samples, unique_clusters):\n",
    "    # Apply DBSCAN clustering algorithm\n",
    "\n",
    "    # Initialize a list to store intra-cluster distances for each cluster\n",
    "    intracluster_distances = []\n",
    "    num_points_in_cluster = []\n",
    "\n",
    "    # Iterate over each unique cluster label\n",
    "    for cluster in unique_clusters:\n",
    "        if cluster != -1:  # Skip noise points labeled as -1\n",
    "            # Get points that belong to the current cluster\n",
    "            cluster_points = data[data['Cluster'] == cluster][['Latitude', 'Longitude']]\n",
    "            num_points_in_cluster.append(len(cluster_points))\n",
    "            if len(cluster_points) > 1:  # Ensure there are at least 2 points in the cluster\n",
    "                # Calculate pairwise Euclidean distances between all points in the cluster\n",
    "                distances = euclidean_distances(cluster_points, cluster_points)\n",
    "                # Extract the upper triangular part of the distance matrix (excluding the diagonal)\n",
    "                upper_triangular_sum = np.sum(distances[np.triu_indices(len(distances), k=1)])\n",
    "                # Calculate the number of elements in the upper triangular part\n",
    "                num_elements = (len(cluster_points) * (len(cluster_points) - 1)) / 2\n",
    "                # Calculate the average distance\n",
    "                intracluster_distance = upper_triangular_sum / num_elements\n",
    "                # Append the calculated average intra-cluster distance to the list\n",
    "                #print(intracluster_distance)\n",
    "                intracluster_distances.append(intracluster_distance)\n",
    "            else:\n",
    "                # If there is only one point in the cluster, the intra-cluster distance is 0\n",
    "                intracluster_distances.append(0)\n",
    "        else:\n",
    "            # Handle noise points separately\n",
    "            intracluster_distances.append(0)\n",
    "            num_points_in_cluster.append(0)\n",
    "\n",
    "    # Return the list of average intra-cluster distances for the current data\n",
    "    return [intracluster_distances, num_points_in_cluster]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95abb407-69ce-452f-8a9e-932fec360cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clusterdata(data_list, eps, min_samples):\n",
    "  newdata = pd.DataFrame(columns = ['Hour', 'Latitude', 'Longitude', 'SOG', 'Heading', 'Cluster', 'Size', 'IntraClusterDistance'])\n",
    "  for i in range(len(data_list)):\n",
    "    #print(i)\n",
    "    if data_list[i].shape[0] <= 1:\n",
    "      continue\n",
    "    model = DBSCAN(eps = eps, min_samples = min_samples, metric = clustermetric).fit(data_list[i][['Latitude', 'Longitude', 'SOG', 'Heading']])\n",
    "    labels = model.labels_\n",
    "    # Calculate intra-cluster distances for the current hour's data\n",
    "    # isolate unique labels\n",
    "    uniquelabels = []\n",
    "    for j in range(len(labels)):\n",
    "      if labels[j] in uniquelabels:\n",
    "        continue\n",
    "      else:\n",
    "        uniquelabels.append(labels[j])\n",
    "    uniquelabels.sort()\n",
    "    tempdata = data_list[i].assign(IntraClusterDistance = np.zeros(data_list[i].shape[0]))\n",
    "    tempdata.insert(tempdata.shape[1] - 1, 'Cluster', labels, True)\n",
    "    tempdata.insert(tempdata.shape[1] - 1, 'Size', np.zeros(tempdata.shape[0]))\n",
    "\n",
    "    tempdata.insert(0, 'AvgHead', np.zeros(tempdata.shape[0]))\n",
    "    tempdata.insert(0, 'AvgLon', np.zeros(tempdata.shape[0]))\n",
    "    tempdata.insert(0, 'AvgLat', np.zeros(tempdata.shape[0]))\n",
    "\n",
    "\n",
    "    for label in uniquelabels:\n",
    "      latsum = 0\n",
    "      lonsum = 0\n",
    "      headsum = 0\n",
    "      labelcount = 0\n",
    "      for lat in tempdata[tempdata['Cluster'] == label]['Latitude']:\n",
    "        latsum += lat\n",
    "        labelcount += 1\n",
    "      for lon in tempdata[tempdata['Cluster'] == label]['Longitude']:\n",
    "        lonsum += lon\n",
    "      for head in tempdata[tempdata['Cluster'] == label]['Heading']:\n",
    "        headsum += float(head)\n",
    "      for row in range(tempdata.shape[0]):\n",
    "        if tempdata.iloc[row]['Cluster'] == label:\n",
    "          tempdata.iloc[row,0] = latsum / labelcount\n",
    "          tempdata.iloc[row,1] = lonsum / labelcount\n",
    "          tempdata.iloc[row,2] = headsum / labelcount\n",
    "\n",
    "    distances = calculate_intracluster_distance_dbscan(tempdata, eps, min_samples, uniquelabels)\n",
    "\n",
    "    for k in range(tempdata.shape[0]):\n",
    "      if uniquelabels[0] == -1:\n",
    "        tempdata.iloc[k,13] = distances[0][tempdata.iloc[k]['Cluster'] + 1]\n",
    "        tempdata.iloc[k,12] = distances[1][tempdata.iloc[k]['Cluster'] + 1]\n",
    "      else:\n",
    "        tempdata.iloc[k,13] = distances[0][tempdata.iloc[k]['Cluster']]\n",
    "        tempdata.iloc[k,12] = distances[1][tempdata.iloc[k]['Cluster']]\n",
    "\n",
    "    tempdata.insert(0, 'Hour',  np.ones(tempdata.shape[0]) * i)\n",
    "    tempdata = tempdata[['Hour', 'Latitude', 'Longitude', 'SOG', 'Heading', 'Cluster', 'Size', 'IntraClusterDistance', 'AvgLat', 'AvgLon', 'AvgHead']]\n",
    "    newdata = pd.concat([newdata, tempdata])\n",
    "  return newdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8b783b-9f92-4d54-bc83-3865204b94ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "################### MAIN FUNCTION ######################\n",
    "\n",
    "# csv should be a file path\n",
    "def cluster(csv, eps, min_samples):\n",
    "    df = pd.read_csv(csv)\n",
    "    trange = time_split(df)\n",
    "    clustered = clusterdata(trange, eps, min_samples)\n",
    "    return clustered.to_csv(\"ClusterData.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
